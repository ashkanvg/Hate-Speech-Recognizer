# Centralized and Federated Bert-Based Hate-Speech Recognition

## Abstract
_Content warning: This paper contains unfiltered content reported by Hate Speech Datasets that may be offensive to readers._

Hate speech recognition is a critical task for maintaining healthy online communities. This paper explores the efficacy of Federated Learning (FL) in enhancing hate speech detection models compared to traditional centralized approaches. We evaluate several state-of-the-art centralized models, including BERT-based models, Random Forest, Decision Tree, K-Nearest Neighbors (KNN), and Logistic Regression, and introduce their federated counterparts, facilitating distributed training across multiple devices while preserving data privacy. Our experimental results, benchmarked using F1 score and accuracy metrics, indicate that FL models outperform centralized models by a significant margin, achieving over $7\%$ higher accuracy. These findings underscore the potential of Federated Learning to improve the robustness and performance of hate speech recognition systems, paving the way for more secure and effective content moderation strategies.

## Files


## Quick Start


## Datasets

### Datasets Information


### Datasets Visualization


## Evaluation




## Cite:
